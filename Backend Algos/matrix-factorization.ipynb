{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = pd.read_csv('apps.csv')\n",
    "users = pd.read_csv('users.csv')\n",
    "jobs = pd.read_csv('jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_JobID = apps['JobID'].unique()\n",
    "unique_UserID = apps['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "user_new2old_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    user_new2old_id_dict[j] = u\n",
    "    j += 1\n",
    "j = 0\n",
    "job_old2new_id_dict = dict()\n",
    "job_new2old_id_dict = dict()\n",
    "for i in unique_JobID:\n",
    "    job_old2new_id_dict[i] = j\n",
    "    job_new2old_id_dict[j] = i\n",
    "    j += 1\n",
    "\n",
    "# Then, use the generated dictionaries to reindex UserID and JobID in the data_df\n",
    "user_list = apps['UserID'].values\n",
    "job_list = apps['JobID'].values\n",
    "for j in range(len(apps)):\n",
    "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
    "    job_list[j] = job_old2new_id_dict[job_list[j]]\n",
    "apps['UserID'] = user_list\n",
    "apps['JobID'] = job_list\n",
    "\n",
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "train_index = np.random.random(len(apps)) <= 0.7\n",
    "train_df = apps[train_index]\n",
    "test_df = apps[~train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/qfrhvmb90676tpsym70kql640000gn/T/ipykernel_24961/3800284669.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['Applied?'] = 1\n",
      "/var/folders/cj/qfrhvmb90676tpsym70kql640000gn/T/ipykernel_24961/3800284669.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Applied?'] = 1\n"
     ]
    }
   ],
   "source": [
    "train_df['Applied?'] = 1\n",
    "test_df['Applied?'] = 1\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# generate train_mat and test_mat\n",
    "num_users = len(apps['UserID'].unique())\n",
    "num_jobs = len(apps['JobID'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['Applied?'].values, (train_df['UserID'].values, train_df['JobID'].values)), shape=(num_users, num_jobs)).astype(float).toarray()\n",
    "test_mat = coo_matrix((test_df['Applied?'].values, (test_df['UserID'].values, test_df['JobID'].values)), shape=(num_users, num_jobs)).astype(float).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF:\n",
    "    def __init__(self, train_mat, test_mat, latent=5, lr=0.01, reg=0.01):\n",
    "        self.train_mat = train_mat  # the training rating matrix of size (#user, #movie)\n",
    "        self.test_mat = test_mat  # the training rating matrix of size (#user, #movie)\n",
    "\n",
    "        self.latent = latent  # the latent dimension\n",
    "        self.lr = lr  # learning rate\n",
    "        self.reg = reg  # regularization weight, i.e., the lambda in the objective function\n",
    "\n",
    "        self.num_users, self.num_jobs = train_mat.shape\n",
    "\n",
    "        self.sample_user, self.sample_movie = self.train_mat.nonzero()  # get the user-movie paris having ratings in train_mat\n",
    "        self.num_sample = len(self.sample_user)  # the number of user-movie pairs having ratings in train_mat\n",
    "\n",
    "        self.train_indicator_mat = 1.0 * (train_mat > 0)  # binary matrix to indicate whether s user-movie pair has rating or not in train_mat\n",
    "        self.test_indicator_mat = 1.0 * (test_mat > 0)  # binary matrix to indicate whether s user-movie pair has rating or not in test_mat\n",
    "\n",
    "        self.P = np.random.random((self.num_users, self.latent))  # latent factors for users, size (#user, self.latent), randomly initialized\n",
    "        self.Q = np.random.random((self.num_jobs, self.latent))  # latent factors for users, size (#movie, self.latent), randomly initialized\n",
    "\n",
    "    def train(self, epoch=20, verbose=True):\n",
    "        \"\"\"\n",
    "        Goal: Write your code to train your matrix factorization model for epoch iterations in this function\n",
    "        Input: epoch -- the number of training epoch\n",
    "        Output: epoch_loss_list -- a list recording the training loss for each epoch\n",
    "                epoch_test_RMSE_list -- a list recording the testing RMSE after each training epoch\n",
    "        \"\"\"\n",
    "        epoch_loss_list = []\n",
    "        epoch_test_RMSE_list = []\n",
    "        for ep in range(epoch):\n",
    "            \"\"\"\n",
    "            Write your code here to implement the training process for one epoch,\n",
    "            and at the end of each epoch, print out the epoch number, the training loss after this epoch,\n",
    "            and the test RMSE after this epoch\n",
    "            \"\"\"\n",
    "            random_indices = np.random.permutation(self.num_sample)\n",
    "            total_loss = 0\n",
    "            for idx in random_indices:\n",
    "              u, i = self.sample_user[idx], self.sample_movie[idx]\n",
    "              pred_val = np.dot(self.P[u], self.Q[i])\n",
    "              error = pred_val - self.train_mat[u, i]\n",
    "              total_loss += error ** 2\n",
    "              self.P[u] -= self.lr * ((error * self.Q[i]) + self.reg * self.P[u])\n",
    "              self.Q[i] -= self.lr * ((error * self.P[u]) + self.reg * self.Q[i])\n",
    "\n",
    "            total_loss /= self.num_sample\n",
    "            epoch_loss_list.append(total_loss)\n",
    "\n",
    "            test_RMSE = self.calculate_RMSE(self.predict(), self.test_mat)\n",
    "            epoch_test_RMSE_list.append(test_RMSE)\n",
    "\n",
    "            if verbose:\n",
    "              print(f\"Epoch {ep + 1} -- Training Loss: {total_loss}, Test RMSE: {test_RMSE}\")\n",
    "\n",
    "            \"\"\"\n",
    "            End of your code for this function\n",
    "            \"\"\"\n",
    "        return epoch_loss_list, epoch_test_RMSE_list\n",
    "\n",
    "    def calculate_RMSE(self, prediction_mat, true_mat):\n",
    "      num_ratings = np.sum(true_mat > 0)\n",
    "      squared_error = np.sum(((prediction_mat - true_mat) ** 2) * (true_mat > 0))\n",
    "      mean_squared_error = squared_error / num_ratings\n",
    "      RMSE = np.sqrt(mean_squared_error)\n",
    "      return RMSE\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        prediction_mat = np.matmul(self.P, self.Q.T)\n",
    "        return prediction_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Training Loss: 0.23639215154879395, Test RMSE: 0.429027993444168\n",
      "Epoch 2 -- Training Loss: 0.14438695224259404, Test RMSE: 0.3632399272597542\n",
      "Epoch 3 -- Training Loss: 0.10158350053747651, Test RMSE: 0.32180124774530583\n",
      "Epoch 4 -- Training Loss: 0.0773873671576295, Test RMSE: 0.2928646669080056\n",
      "Epoch 5 -- Training Loss: 0.06198057747546223, Test RMSE: 0.2712711254943288\n",
      "Epoch 6 -- Training Loss: 0.051371279368963435, Test RMSE: 0.25437365944437407\n",
      "Epoch 7 -- Training Loss: 0.04365089135253524, Test RMSE: 0.24069006844198854\n",
      "Epoch 8 -- Training Loss: 0.03780335759008195, Test RMSE: 0.22933890378574653\n",
      "Epoch 9 -- Training Loss: 0.03323910400472229, Test RMSE: 0.21973429340009334\n",
      "Epoch 10 -- Training Loss: 0.0295885654675396, Test RMSE: 0.21147847060853936\n",
      "Epoch 11 -- Training Loss: 0.026610870322590484, Test RMSE: 0.20429248977747375\n",
      "Epoch 12 -- Training Loss: 0.024140061647593424, Test RMSE: 0.1979694969688579\n",
      "Epoch 13 -- Training Loss: 0.022061672350447252, Test RMSE: 0.19235738805632233\n",
      "Epoch 14 -- Training Loss: 0.02029169859570236, Test RMSE: 0.18733029576243604\n",
      "Epoch 15 -- Training Loss: 0.018767235527144415, Test RMSE: 0.1827951871824406\n",
      "Epoch 16 -- Training Loss: 0.017443033601330624, Test RMSE: 0.17867546183925492\n",
      "Epoch 17 -- Training Loss: 0.016281327287148324, Test RMSE: 0.17491981227927644\n",
      "Epoch 18 -- Training Loss: 0.015254786594692126, Test RMSE: 0.17147004629291349\n",
      "Epoch 19 -- Training Loss: 0.014342013360416548, Test RMSE: 0.16829022198051985\n",
      "Epoch 20 -- Training Loss: 0.013524918123722321, Test RMSE: 0.16534554413183647\n",
      "Epoch 21 -- Training Loss: 0.012789295161879969, Test RMSE: 0.16261147528380912\n",
      "Epoch 22 -- Training Loss: 0.012123800045070361, Test RMSE: 0.16006260265533798\n",
      "Epoch 23 -- Training Loss: 0.011518570419372846, Test RMSE: 0.15767336146985497\n",
      "Epoch 24 -- Training Loss: 0.010966297585508546, Test RMSE: 0.15543461341095743\n",
      "Epoch 25 -- Training Loss: 0.010459590076888587, Test RMSE: 0.15332409570483818\n",
      "Epoch 26 -- Training Loss: 0.009994034375956183, Test RMSE: 0.1513347845590888\n",
      "Epoch 27 -- Training Loss: 0.009564055223014503, Test RMSE: 0.14945324414143688\n",
      "Epoch 28 -- Training Loss: 0.009165876010632137, Test RMSE: 0.14767246774768794\n",
      "Epoch 29 -- Training Loss: 0.00879608287756705, Test RMSE: 0.14597700958534465\n",
      "Epoch 30 -- Training Loss: 0.008451891630263305, Test RMSE: 0.14436891433128227\n"
     ]
    }
   ],
   "source": [
    "mf = MF(train_mat, test_mat, latent=5, lr=0.01, reg=0.001)\n",
    "epoch_loss_list, epoch_test_RMSE_list = mf.train(epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALYSIS**\n",
    "\n",
    "Now, for a particular user, I will try and find out which jobs should be recommended to him the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mat = mf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83139616, 1.16377256, 0.98245068, ..., 0.93491823, 1.06735357,\n",
       "        0.59623074],\n",
       "       [0.73712132, 1.17268451, 0.99184864, ..., 0.79149004, 0.91911124,\n",
       "        0.45304032],\n",
       "       [0.93791125, 1.02148229, 1.03478344, ..., 0.88668511, 1.12000929,\n",
       "        0.81596457],\n",
       "       ...,\n",
       "       [1.01357159, 0.82421389, 0.94131562, ..., 0.93642453, 1.18115029,\n",
       "        1.03317214],\n",
       "       [0.87179319, 0.86723909, 0.9051489 , ..., 0.87294544, 1.13968451,\n",
       "        0.77212501],\n",
       "       [0.89403046, 1.06152702, 0.97834624, ..., 0.67356837, 0.83193576,\n",
       "        0.89702833]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_recommendation_for_user(user_real_id):\n",
    "    user_id = user_old2new_id_dict[user_real_id]\n",
    "    arr = pred_mat[user_id]\n",
    "    indexed_arr = list(enumerate(arr))\n",
    "\n",
    "    # Sort the array of tuples based on probabilities in descending order\n",
    "    sorted_arr = sorted(indexed_arr, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract the indices of the top 10 probabilities\n",
    "    top_10_indices = [job_new2old_id_dict[index] for index, _ in sorted_arr[:10]]\n",
    "\n",
    "    best_jobs = jobs[jobs['JobID'].isin(top_10_indices)]\n",
    "    print(\"Top 10 jobs for the user are: \\n\")\n",
    "    \n",
    "    for _, job in best_jobs.iterrows():\n",
    "        print(job['Title'])\n",
    "\n",
    "    return best_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 jobs for the user are: \n",
      "\n",
      "Shipping and Receiving Supervisor\n",
      "Receptionist/Patient Check Out\n",
      "Receptionist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobID</th>\n",
       "      <th>WindowID</th>\n",
       "      <th>Title</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Zip5</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>DescCleaned</th>\n",
       "      <th>ReqCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61213</th>\n",
       "      <td>590247</td>\n",
       "      <td>6</td>\n",
       "      <td>Shipping and Receiving Supervisor</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-08 02:02:18.11</td>\n",
       "      <td>2012-07-07 23:59:00</td>\n",
       "      <td>shipping and receiving supervisor- night shift...</td>\n",
       "      <td>experience/education requirements 5 years of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65262</th>\n",
       "      <td>631626</td>\n",
       "      <td>6</td>\n",
       "      <td>Receptionist/Patient Check Out</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>NY</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-20 00:25:30.393</td>\n",
       "      <td>2012-06-19 23:59:00</td>\n",
       "      <td>receptionist/patient check out - busy obgyn pr...</td>\n",
       "      <td>please refer to the job description to view th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114600</th>\n",
       "      <td>1105210</td>\n",
       "      <td>6</td>\n",
       "      <td>Receptionist</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>US</td>\n",
       "      <td>44144.0</td>\n",
       "      <td>2012-05-30 12:37:20.993</td>\n",
       "      <td>2012-06-29 23:59:00</td>\n",
       "      <td>receptionist purpose greet customers and visit...</td>\n",
       "      <td>job requirements - education background, train...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          JobID  WindowID                              Title       City State  \\\n",
       "61213    590247         6  Shipping and Receiving Supervisor    Atlanta    GA   \n",
       "65262    631626         6     Receptionist/Patient Check Out  Rochester    NY   \n",
       "114600  1105210         6                       Receptionist  Cleveland    OH   \n",
       "\n",
       "       Country     Zip5                StartDate              EndDate  \\\n",
       "61213       US      NaN   2012-06-08 02:02:18.11  2012-07-07 23:59:00   \n",
       "65262       US      NaN  2012-05-20 00:25:30.393  2012-06-19 23:59:00   \n",
       "114600      US  44144.0  2012-05-30 12:37:20.993  2012-06-29 23:59:00   \n",
       "\n",
       "                                              DescCleaned  \\\n",
       "61213   shipping and receiving supervisor- night shift...   \n",
       "65262   receptionist/patient check out - busy obgyn pr...   \n",
       "114600  receptionist purpose greet customers and visit...   \n",
       "\n",
       "                                               ReqCleaned  \n",
       "61213   experience/education requirements 5 years of s...  \n",
       "65262   please refer to the job description to view th...  \n",
       "114600  job requirements - education background, train...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_recommendation_for_user(963422)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>JobID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UserID, JobID, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apps[apps['UserID'] == 963422]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = pd.read_csv('apps.csv')\n",
    "jobs = pd.read_csv('jobs.csv')\n",
    "users = pd.read_csv('users.csv')\n",
    "user_history = pd.read_csv('work_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = users[users.Split==\"Train\"]\n",
    "test_user = users[users.Split==\"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "hit = []\n",
    "\n",
    "for _, user in tqdm(test_user.iterrows(), total=len(test_user)):\n",
    "    predictions = getPredictions(input_data, 20)\n",
    "\n",
    "    found_applied = False\n",
    "    for job in predictions:\n",
    "        applied_to = apps[(apps['JobID'] == job) & (apps['UserID'] == id)]\n",
    "        if (len(applied_to) > 0):\n",
    "            found_applied = True\n",
    "            break\n",
    "    \n",
    "    if found_applied:\n",
    "        hit.append(1)\n",
    "    else:\n",
    "        hit.append(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
